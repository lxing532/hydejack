---
layout: post
title: Diagnosing and Improving Topic Models by Analyzing Posterior Variability
tags: [PUBLICATION]
description: >
  AAAI Conference on Artificial Intelligence (AAAI), New Orleans, Louisiana. February 2018.
---
- **Authors**: Linzi Xing, Michael J. Paul
- **Paper**: [Click here](http://deanxing.net/public/paper/aaai18_paper.pdf).

Bayesian inference methods for probabilistic topic models can quantify uncertainty in the parameters, which has primar- ily been used to increase the robustness of parameter esti- mates. In this work, we explore other rich information that can be obtained by analyzing the posterior distributions in topic models. Experimenting with latent Dirichlet allocation on two datasets, we propose ideas incorporating information about the posterior distributions at the topic level and at the word level. At the topic level, we propose a metric called topic stability that measures the variability of the topic pa- rameters under the posterior. We show that this metric is cor- related with human judgments of topic quality as well as with the consistency of topics appearing across multiple models. At the word level, we experiment with different methods for adjusting individual word probabilities within topics based on their uncertainty. Humans prefer words ranked by our ad- justed estimates nearly twice as often when compared to the traditional approach. Finally, we describe how the ideas pre- sented in this work could potentially applied to other predic- tive or exploratory models in future work.
